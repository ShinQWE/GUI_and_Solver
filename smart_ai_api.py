# smart_ai_api.py - –¢–û–õ–¨–ö–û AI –†–ï–ñ–ò–ú
import sys
import os
import json
import subprocess
from http.server import HTTPServer, BaseHTTPRequestHandler

class SmartAIHandler(BaseHTTPRequestHandler):
    
    def __init__(self, *args, **kwargs):
        self.available_models = self.detect_available_models()
        super().__init__(*args, **kwargs)
    
    def detect_available_models(self):
        """–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –æ–ø—Ä–µ–¥–µ–ª—è–µ—Ç –¥–æ—Å—Ç—É–ø–Ω—ã–µ –º–æ–¥–µ–ª–∏ Ollama"""
        print("üîç –ü–æ–∏—Å–∫ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π...")
        available_models = []
        
        try:
            result = subprocess.run(['ollama', 'list'], capture_output=True, text=True, timeout=10)
            if result.returncode == 0:
                lines = result.stdout.strip().split('\n')
                for line in lines[1:]:
                    if line.strip():
                        model_name = line.split()[0]
                        available_models.append(model_name)
                        print(f"‚úÖ –ù–∞–π–¥–µ–Ω–∞ –º–æ–¥–µ–ª—å: {model_name}")
            
            if not available_models:
                print("‚ùå –ú–æ–¥–µ–ª–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã! –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ: ollama pull llama3.2:1b")
                
        except Exception as e:
            print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø–æ–∏—Å–∫–∞ –º–æ–¥–µ–ª–µ–π: {e}")
        
        return available_models
    
    def do_OPTIONS(self):
        self.send_response(200)
        self.send_header('Access-Control-Allow-Origin', '*')
        self.send_header('Access-Control-Allow-Methods', 'POST, OPTIONS')
        self.send_header('Access-Control-Allow-Headers', 'Content-Type')
        self.end_headers()
    
    def do_POST(self):
        if self.path == '/api/analyze':
            print(f"üì® –ü–æ–ª—É—á–µ–Ω –∑–∞–ø—Ä–æ—Å (–¥–æ—Å—Ç—É–ø–Ω–æ –º–æ–¥–µ–ª–µ–π: {len(self.available_models)})")
            
            try:
                if not self.available_models:
                    raise Exception("AI –º–æ–¥–µ–ª–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã! –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ: ollama pull llama3.2:1b")
                
                # –ß–∏—Ç–∞–µ–º –¥–∞–Ω–Ω—ã–µ
                content_length = int(self.headers['Content-Length'])
                post_data = self.rfile.read(content_length)
                request_data = json.loads(post_data.decode('utf-8'))
                
                # –ò–∑–≤–ª–µ–∫–∞–µ–º –¥–∏–∞–≥–Ω–æ–∑
                ib_data = request_data["–ò—Å—Ç–æ—Ä–∏—è –±–æ–ª–µ–∑–Ω–∏ –∏–ª–∏ –Ω–∞–±–ª—é–¥–µ–Ω–∏–π v.4"]
                ib_id = list(ib_data.keys())[0]
                patient_data = ib_data[ib_id]["–î–∞–Ω–Ω—ã–µ"]["–°–≤–µ–¥–µ–Ω–∏—è –ø—Ä–∏ –æ–±—Ä–∞—â–µ–Ω–∏–∏"]
                diagnosis = patient_data.get("–ö–ª–∏–Ω–∏—á–µ—Å–∫–∏–π –¥–∏–∞–≥–Ω–æ–∑", {}).get("–ó–Ω–∞—á–µ–Ω–∏–µ", "–Ω–µ —É–∫–∞–∑–∞–Ω")
                
                # –ò–°–ü–û–õ–¨–ó–£–ï–ú –¢–û–õ–¨–ö–û AI
                recommendations = self.use_ai_system(diagnosis)
                
                # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –æ—Ç–≤–µ—Ç
                self.send_response(200)
                self.send_header('Content-type', 'application/json')
                self.send_header('Access-Control-Allow-Origin', '*')
                self.end_headers()
                
                response = {
                    'success': True,
                    'recommendations': recommendations,
                    'mode': 'ai'
                }
                
                self.wfile.write(json.dumps(response, ensure_ascii=False).encode())
                print("‚úÖ AI —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω—ã")
                
            except Exception as e:
                print(f"‚ùå –û—à–∏–±–∫–∞: {e}")
                self.send_error_response(str(e))
                
        else:
            self.send_response(404)
            self.end_headers()
    
    def use_ai_system(self, diagnosis):
        """–ò—Å–ø–æ–ª—å–∑—É–µ—Ç —Ä–µ–∞–ª—å–Ω—ã–µ AI –º–æ–¥–µ–ª–∏ —á–µ—Ä–µ–∑ –ø—Ä—è–º–æ–µ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ"""
        try:
            print(f"üéØ –ó–∞–ø—É—Å–∫ AI –¥–ª—è –¥–∏–∞–≥–Ω–æ–∑–∞: {diagnosis}")
            
            # –î–æ–±–∞–≤–ª—è–µ–º –ø—É—Ç—å –∫ –∏—Ö –ø—Ä–æ–µ–∫—Ç—É
            sys.path.append('./medical_assistant')
            
            # –ü—Ä—è–º–æ–π –∏–º–ø–æ—Ä—Ç –∏—Ö —Å–∏—Å—Ç–µ–º—ã
            from core import MedicalAssistant
            
            # –°–æ–∑–¥–∞–µ–º –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç
            assistant = MedicalAssistant(model="llama3.2:1b")
            
            # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ –ø–∞—Ü–∏–µ–Ω—Ç–∞ –≤ –Ω—É–∂–Ω–æ–º —Ñ–æ—Ä–º–∞—Ç–µ
            patient_data_formatted = {
                "–ö–ª–∏–Ω–∏—á–µ—Å–∫–∏–π –¥–∏–∞–≥–Ω–æ–∑": {
                    "–¢–∏–ø": "–¢–µ–∫—Å—Ç–æ–≤–æ–µ", 
                    "–ó–Ω–∞—á–µ–Ω–∏–µ": diagnosis
                }
            }
            
            print("üìö –ó–∞–≥—Ä—É–∑–∫–∞ –º–µ–¥–∏—Ü–∏–Ω—Å–∫–∏—Ö –ø–∞—Ä–∞–≥—Ä–∞—Ñ–æ–≤...")
            # –ó–∞–≥—Ä—É–∂–∞–µ–º —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–µ –ø–∞—Ä–∞–≥—Ä–∞—Ñ—ã
            vault_content = assistant.load_relevant_paragraphs(patient_data_formatted)
            print(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ –ø–∞—Ä–∞–≥—Ä–∞—Ñ–æ–≤: {len(vault_content)}")
            
            print("üîç –°–æ–∑–¥–∞–Ω–∏–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤...")
            # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —ç–º–±–µ–¥–¥–∏–Ω–≥–∏
            vault_embeddings = assistant.generate_embeddings(vault_content)
            print(f"‚úÖ –°–æ–∑–¥–∞–Ω–æ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤: {vault_embeddings.shape}")
            
            print("üí¨ –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Å–∏—Å—Ç–µ–º–Ω–æ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏—è...")
            # –ü–æ–ª—É—á–∞–µ–º —Å–∏—Å—Ç–µ–º–Ω–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ
            system_message = assistant.get_system_message_by_diagnosis(patient_data_formatted)
            
            print("ü§ñ –ó–∞–ø—Ä–æ—Å –∫ AI –º–æ–¥–µ–ª–∏...")
            # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
            user_input = f"–ù–∞–∑–Ω–∞—á—å—Ç–µ –ª–µ—á–µ–Ω–∏–µ –¥–ª—è –ø–∞—Ü–∏–µ–Ω—Ç–∞ —Å –¥–∏–∞–≥–Ω–æ–∑–æ–º: {diagnosis}"
            
            recommendation = assistant.ollama_chat(
                user_input,
                system_message,
                vault_embeddings,
                vault_content,
                assistant.model,
                assistant.conversation_history,
                patient_data_formatted
            )
            
            print("üéâ AI —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ —É—Å–ø–µ—à–Ω–æ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω—ã!")
            return recommendation
            
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ AI —Å–∏—Å—Ç–µ–º—ã: {e}")
            raise Exception(f"–û—à–∏–±–∫–∞ AI —Å–∏—Å—Ç–µ–º—ã: {str(e)}")
    
    def send_error_response(self, error_msg):
        self.send_response(500)
        self.send_header('Content-type', 'application/json')
        self.send_header('Access-Control-Allow-Origin', '*')
        self.end_headers()
        self.wfile.write(json.dumps({
            'success': False,
            'error': error_msg
        }).encode())

def run_smart_server():
    print("üöÄ –£–ú–ù–´–ô –ú–ï–î–ò–¶–ò–ù–°–ö–ò–ô AI –°–ï–†–í–ï–†")
    print("üìç http://127.0.0.1:5000")
    print("üîç –ò—Å–ø–æ–ª—å–∑—É–µ—Ç —Ç–æ–ª—å–∫–æ —Ä–µ–∞–ª—å–Ω—ã–µ AI –º–æ–¥–µ–ª–∏")
    print("‚ùå –û—Ñ—Ñ–ª–∞–π–Ω —Ä–µ–∂–∏–º –æ—Ç–∫–ª—é—á–µ–Ω")
    print("‚èπÔ∏è  Ctrl+C –¥–ª—è –æ—Å—Ç–∞–Ω–æ–≤–∫–∏\n")
    
    server = HTTPServer(('127.0.0.1', 5000), SmartAIHandler)
    
    try:
        server.serve_forever()
    except KeyboardInterrupt:
        print("\n‚èπÔ∏è –û—Å—Ç–∞–Ω–æ–≤–∫–∞ —Å–µ—Ä–≤–µ—Ä–∞")

if __name__ == '__main__':
    run_smart_server()