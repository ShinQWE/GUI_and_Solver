import torch
import ollama
import os
import json
import glob
import re
from openai import OpenAI
import tkinter as tk
from tkinter import filedialog
import os
import json
import glob
import shutil


class MedicalAssistant:
    def __init__(self, model="mistral:7b"):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –º–µ–¥–∏—Ü–∏–Ω—Å–∫–æ–≥–æ –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–∞

        Args:
            model (str): –ù–∞–∑–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏ Ollama –¥–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
        """
        self.model = model
        self.client = OpenAI(
            base_url='http://localhost:11434/v1',
            api_key='llama3'
        )
        self.conversation_history = []
        self.patient_data = {}
        self.vault_content = []
        self.vault_embeddings_tensor = None

        # –¶–≤–µ—Ç–∞ –¥–ª—è –≤—ã–≤–æ–¥–∞ –≤ –∫–æ–Ω—Å–æ–ª—å
        self.PINK = '\033[95m'
        self.CYAN = '\033[96m'
        self.YELLOW = '\033[93m'
        self.NEON_GREEN = '\033[92m'
        self.RESET_COLOR = '\033[0m'

    # –§—É–Ω–∫—Ü–∏—è –¥–ª—è –æ–∫—Ä—ã—Ç–∏—è —Ñ–∞–π–ª–∞, –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Ç–µ–∫—Å—Ç –≤ –≤–∏–¥–µ —Å—Ç—Ä–æ–∫
    def open_file(self, filepath):
        with open(filepath, 'r', encoding='utf-8') as infile:
            return infile.read()

    # –§—É–Ω–∫—Ü–∏—è –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ –¥–∞–Ω–Ω—ã—Ö –ø–∞—Ü–∏–µ–Ω—Ç–∞ –∏–∑ JSON —Ñ–∞–π–ª–∞
    # –£–ø—Ä–æ—â–µ–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è —Å –ª—É—á—à–∏–º —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ–º
    import tkinter as tk
    from tkinter import filedialog
    import os
    import json
    import glob
    import shutil

    def load_patient_data_simple(self, data_path='–ò–ë'):
        try:
            # –°–æ–∑–¥–∞–µ–º –ø–∞–ø–∫—É –ò–ë –µ—Å–ª–∏ –µ–µ –Ω–µ—Ç
            if not os.path.exists(data_path):
                os.makedirs(data_path)
                print(f"–°–æ–∑–¥–∞–Ω–∞ –ø–∞–ø–∫–∞ {data_path}")

            # –û—á–∏—â–∞–µ–º –ø–∞–ø–∫—É –ò–ë –æ—Ç —Å—Ç–∞—Ä—ã—Ö —Ñ–∞–π–ª–æ–≤
            self.clear_ib_folder(data_path)

            # –û—Ç–∫—Ä—ã–≤–∞–µ–º –¥–∏–∞–ª–æ–≥–æ–≤–æ–µ –æ–∫–Ω–æ –¥–ª—è –≤—ã–±–æ—Ä–∞ —Ñ–∞–π–ª–∞
            json_filepath = self.open_file_dialog()

            if not json_filepath:
                print("–§–∞–π–ª –Ω–µ –≤—ã–±—Ä–∞–Ω")
                return {}

            # –ö–æ–ø–∏—Ä—É–µ–º –≤—ã–±—Ä–∞–Ω–Ω—ã–π —Ñ–∞–π–ª –≤ –ø–∞–ø–∫—É –ò–ë
            filename = os.path.basename(json_filepath)
            destination_path = os.path.join(data_path, filename)
            shutil.copy2(json_filepath, destination_path)
            print(f"–§–∞–π–ª —Å–∫–æ–ø–∏—Ä–æ–≤–∞–Ω –≤: {destination_path}")

            # –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞–Ω–Ω—ã–µ –∏–∑ —Å–∫–æ–ø–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ —Ñ–∞–π–ª–∞
            print(f"–ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞–Ω–Ω—ã–µ –∏–∑ —Ñ–∞–π–ª–∞: {filename}")

            with open(destination_path, 'r', encoding='utf-8') as file:
                data = json.load(file)

            # –ò–∑–≤–ª–µ–∫–∞–µ–º –¥–∞–Ω–Ω—ã–µ
            patient_record = list(data["–ò—Å—Ç–æ—Ä–∏—è –±–æ–ª–µ–∑–Ω–∏ –∏–ª–∏ –Ω–∞–±–ª—é–¥–µ–Ω–∏–π v.4"].values())[0]
            patient_info = patient_record["–î–∞–Ω–Ω—ã–µ"]["–°–≤–µ–¥–µ–Ω–∏—è –ø—Ä–∏ –æ–±—Ä–∞—â–µ–Ω–∏–∏"]

            print("\n–î–∞–Ω–Ω—ã–µ –ø–∞—Ü–∏–µ–Ω—Ç–∞:")
            print("=" * 50)

            # –°–æ–∑–¥–∞–µ–º —Å–ª–æ–≤–∞—Ä—å –¥–ª—è –≤–æ–∑–≤—Ä–∞—â–∞–µ–º—ã—Ö –¥–∞–Ω–Ω—ã—Ö
            patient_data = {}

            for field_name, field_data in patient_info.items():
                if isinstance(field_data, dict) and "–ó–Ω–∞—á–µ–Ω–∏–µ" in field_data:
                    value = field_data["–ó–Ω–∞—á–µ–Ω–∏–µ"]

                    if value in [None, "", [], False]:
                        continue

                    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –¥–∞–Ω–Ω—ã–µ –≤ –≤–æ–∑–≤—Ä–∞—â–∞–µ–º—ã–π —Å–ª–æ–≤–∞—Ä—å
                    patient_data[field_name] = {
                        "–¢–∏–ø": field_data.get("–¢–∏–ø", ""),
                        "–ó–Ω–∞—á–µ–Ω–∏–µ": value
                    }

                    # –ü—Ä–æ—Å—Ç—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è
                    if not isinstance(value, list):
                        print(f"‚Ä¢ {field_name}: {value}")

                    # –°–ø–∏—Å–∫–∏ –ø—Ä–æ—Å—Ç—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π
                    elif isinstance(value, list) and value and not isinstance(value[0], dict):
                        print(f"‚Ä¢ {field_name}: {', '.join(map(str, value))}")

                    # –°–ª–æ–∂–Ω—ã–µ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã
                    else:
                        print(f"‚Ä¢ {field_name}:")
                        for item in value:
                            if isinstance(item, dict):
                                for sub_key, sub_value in item.items():
                                    if isinstance(sub_value, dict) and "–ó–Ω–∞—á–µ–Ω–∏–µ" in sub_value:
                                        nested_items = sub_value["–ó–Ω–∞—á–µ–Ω–∏–µ"]
                                        if nested_items:
                                            print(f"  ‚îî‚îÄ‚îÄ {sub_key}:")
                                            for nested_item in nested_items:
                                                if isinstance(nested_item, dict):
                                                    for detail_key, detail_value in nested_item.items():
                                                        if isinstance(detail_value,
                                                                      dict) and "–ó–Ω–∞—á–µ–Ω–∏–µ" in detail_value:
                                                            detail_content = detail_value["–ó–Ω–∞—á–µ–Ω–∏–µ"]
                                                            if detail_content not in [None, "", []]:
                                                                print(f"      ‚îú‚îÄ‚îÄ {detail_key}: {detail_content}")

            print("=" * 50)
            return patient_data

        except Exception as e:
            print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ –¥–∞–Ω–Ω—ã—Ö –ø–∞—Ü–∏–µ–Ω—Ç–∞: {e}")
            return {}

    def clear_ib_folder(self, data_path):
        """–û—á–∏—â–∞–µ—Ç –ø–∞–ø–∫—É –ò–ë –æ—Ç –≤—Å–µ—Ö —Ñ–∞–π–ª–æ–≤"""
        if os.path.exists(data_path):
            for filename in os.listdir(data_path):
                file_path = os.path.join(data_path, filename)
                try:
                    if os.path.isfile(file_path):
                        os.unlink(file_path)
                        print(f"–£–¥–∞–ª–µ–Ω —Å—Ç–∞—Ä—ã–π —Ñ–∞–π–ª: {filename}")
                except Exception as e:
                    print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —É–¥–∞–ª–µ–Ω–∏–∏ —Ñ–∞–π–ª–∞ {filename}: {e}")

    def open_file_dialog(self):
        """–û—Ç–∫—Ä—ã–≤–∞–µ—Ç –¥–∏–∞–ª–æ–≥–æ–≤–æ–µ –æ–∫–Ω–æ –¥–ª—è –≤—ã–±–æ—Ä–∞ JSON —Ñ–∞–π–ª–∞"""
        root = tk.Tk()
        root.withdraw()  # –°–∫—Ä—ã–≤–∞–µ–º –æ—Å–Ω–æ–≤–Ω–æ–µ –æ–∫–Ω–æ
        root.attributes('-topmost', True)  # –ü–æ–≤–µ—Ä—Ö –≤—Å–µ—Ö –æ–∫–æ–Ω

        file_path = filedialog.askopenfilename(
            title="–í—ã–±–µ—Ä–∏—Ç–µ JSON —Ñ–∞–π–ª —Å –¥–∞–Ω–Ω—ã–º–∏ –ø–∞—Ü–∏–µ–Ω—Ç–∞",
            filetypes=[("JSON files", "*.json"), ("All files", "*.*")]
        )

        root.destroy()
        return file_path


    # –§—É–Ω–∫—Ü–∏—è –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –Ω—É–∂–Ω–æ–≥–æ —Ñ–∞–π–ª–∞ –ø–∞—Ä–∞–≥—Ä–∞—Ñ–æ–≤ –Ω–∞ –æ—Å–Ω–æ–≤–µ –¥–∏–∞–≥–Ω–æ–∑–∞
    def get_paragraphs_file_by_diagnosis(self,patient_data):
        """
        –û–ø—Ä–µ–¥–µ–ª—è–µ—Ç –∫–∞–∫–æ–π —Ñ–∞–π–ª –ø–∞—Ä–∞–≥—Ä–∞—Ñ–æ–≤ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –Ω–∞ –æ—Å–Ω–æ–≤–µ –∫–ª–∏–Ω–∏—á–µ—Å–∫–æ–≥–æ –¥–∏–∞–≥–Ω–æ–∑–∞
        """

        base_dir = os.path.dirname(__file__)


        # –ò–∑–≤–ª–µ–∫–∞–µ–º –∫–ª–∏–Ω–∏—á–µ—Å–∫–∏–π –¥–∏–∞–≥–Ω–æ–∑ –∏–∑ –¥–∞–Ω–Ω—ã—Ö –ø–∞—Ü–∏–µ–Ω—Ç–∞
        clinical_diagnosis = ""
        if "–ö–ª–∏–Ω–∏—á–µ—Å–∫–∏–π –¥–∏–∞–≥–Ω–æ–∑" in patient_data:
            clinical_diagnosis = str(patient_data["–ö–ª–∏–Ω–∏—á–µ—Å–∫–∏–π –¥–∏–∞–≥–Ω–æ–∑"]["–ó–Ω–∞—á–µ–Ω–∏–µ"]).lower()

        print(f"–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –¥–∏–∞–≥–Ω–æ–∑: '{clinical_diagnosis}'")

        # –†–µ–≥—É–ª—è—Ä–Ω—ã–µ –≤—ã—Ä–∞–∂–µ–Ω–∏—è –¥–ª—è –ø–æ–∏—Å–∫–∞
        hepatitis_patterns = [
            r'—Ö–≤–≥—Å',  # –•–í–ì–°
            r'–≥–µ–ø–∞—Ç–∏—Ç',  # –≥–µ–ø–∞—Ç–∏—Ç, –≥–µ–ø–∞—Ç–∏—Ç–∞, –≥–µ–ø–∞—Ç–∏—Ç–æ–º –∏ —Ç.–¥.
            r'—Ö—Ä–æ–Ω\w* –≥–µ–ø–∞—Ç–∏—Ç',  # —Ö—Ä–æ–Ω–∏—á–µ—Å–∫–∏–π –≥–µ–ø–∞—Ç–∏—Ç
            r'–≤–∏—Ä—É—Å–Ω\w* –≥–µ–ø–∞—Ç–∏—Ç',  # –≤–∏—Ä—É—Å–Ω—ã–π –≥–µ–ø–∞—Ç–∏—Ç
            r'–≥–µ–ø–∞—Ç–∏—Ç\s*—Å',  # –≥–µ–ø–∞—Ç–∏—Ç —Å, –≥–µ–ø–∞—Ç–∏—Ç—Å
        ]

        # –ü–∞—Ç—Ç–µ—Ä–Ω—ã –¥–ª—è –ø–µ—Ä–µ–ª–æ–º–æ–≤ –∫–ª—é—á–∏—Ü—ã –∏/–∏–ª–∏ –ª–æ–ø–∞—Ç–∫–∏
        fracture_patterns = [
            # –ü–µ—Ä–µ–ª–æ–º(—ã) –∫–ª—é—á–∏—Ü—ã
            r'–ø–µ—Ä–µ–ª–æ–º\w*\s+–∫–ª—é—á–∏—Ü\w*',
            r'–∫–ª—é—á–∏—Ü\w*\s+–ø–µ—Ä–µ–ª–æ–º\w*',

            # –ü–µ—Ä–µ–ª–æ–º(—ã) –ª–æ–ø–∞—Ç–∫–∏
            r'–ø–µ—Ä–µ–ª–æ–º\w*\s+–ª–æ–ø–∞—Ç\w*',
            r'–ª–æ–ø–∞—Ç\w*\s+–ø–µ—Ä–µ–ª–æ–º\w*',

            # –ü–µ—Ä–µ–ª–æ–º(—ã) –∫–ª—é—á–∏—Ü—ã –∏ –ª–æ–ø–∞—Ç–∫–∏
            r'–ø–µ—Ä–µ–ª–æ–º\w*\s+–∫–ª—é—á–∏—Ü\w*\s+–∏\s+–ª–æ–ø–∞—Ç\w*',
            r'–ø–µ—Ä–µ–ª–æ–º\w*\s+–ª–æ–ø–∞—Ç\w*\s+–∏\s+–∫–ª—é—á–∏—Ü\w*',
            r'–∫–ª—é—á–∏—Ü\w*\s+–∏\s+–ª–æ–ø–∞—Ç\w*\s+–ø–µ—Ä–µ–ª–æ–º\w*',

            # –ü–µ—Ä–µ–ª–æ–º(—ã) –∫–ª—é—á–∏—Ü—ã –∏–ª–∏ –ª–æ–ø–∞—Ç–∫–∏
            r'–ø–µ—Ä–µ–ª–æ–º\w*\s+–∫–ª—é—á–∏—Ü\w*\s+–∏–ª–∏\s+–ª–æ–ø–∞—Ç\w*',
            r'–ø–µ—Ä–µ–ª–æ–º\w*\s+–ª–æ–ø–∞—Ç\w*\s+–∏–ª–∏\s+–∫–ª—é—á–∏—Ü\w*',
        ]

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–∞—Ç—Ç–µ—Ä–Ω—ã –¥–ª—è –≥–µ–ø–∞—Ç–∏—Ç–∞
        for pattern in hepatitis_patterns:
            if re.search(pattern, clinical_diagnosis):
                paragraphs_file = os.path.join(base_dir, "data", "–•—Ä–æ–Ω–∏—á–µ—Å–∫–∏–π –≤–∏—Ä—É—Å–Ω—ã–π –≥–µ–ø–∞—Ç–∏—Ç –° (–•–í–ì–°) –ø–∞—Ä–∞–≥—Ä–∞—Ñ—ã.txt")
                print(f"‚úÖ –í—ã–±—Ä–∞–Ω —Ñ–∞–π–ª –¥–ª—è –≥–µ–ø–∞—Ç–∏—Ç–∞ (–Ω–∞–π–¥–µ–Ω –ø–∞—Ç—Ç–µ—Ä–Ω: '{pattern}')")
                return paragraphs_file

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–∞—Ç—Ç–µ—Ä–Ω—ã –¥–ª—è –ø–µ—Ä–µ–ª–æ–º–æ–≤
        for pattern in fracture_patterns:
            if re.search(pattern, clinical_diagnosis):
                paragraphs_file = os.path.join(base_dir, "data", "–ü–µ—Ä–µ–ª–æ–º—ã –∫–ª—é—á–∏—Ü—ã –∏ –ª–æ–ø–∞—Ç–∫–∏ –ø–∞—Ä–∞–≥—Ä–∞—Ñ—ã.txt")
                print(f"‚úÖ –í—ã–±—Ä–∞–Ω —Ñ–∞–π–ª –¥–ª—è –ø–µ—Ä–µ–ª–æ–º–æ–≤ (–Ω–∞–π–¥–µ–Ω –ø–∞—Ç—Ç–µ—Ä–Ω: '{pattern}')")
                return paragraphs_file

        # –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é –∏—Å–ø–æ–ª—å–∑—É–µ–º –≥–µ–ø–∞—Ç–∏—Ç, –µ—Å–ª–∏ –¥–∏–∞–≥–Ω–æ–∑ –Ω–µ —Ä–∞—Å–ø–æ–∑–Ω–∞–Ω
        paragraphs_file = os.path.join(base_dir, "data", "–•—Ä–æ–Ω–∏—á–µ—Å–∫–∏–π –≤–∏—Ä—É—Å–Ω—ã–π –≥–µ–ø–∞—Ç–∏—Ç –° (–•–í–ì–°) –ø–∞—Ä–∞–≥—Ä–∞—Ñ—ã.txt")
        print("‚ö†Ô∏è  –í—ã–±—Ä–∞–Ω —Ñ–∞–π–ª –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é (–≥–µ–ø–∞—Ç–∏—Ç) - –¥–∏–∞–≥–Ω–æ–∑ –Ω–µ —Ä–∞—Å–ø–æ–∑–Ω–∞–Ω")
        return paragraphs_file

    # –§—É–Ω–∫—Ü–∏—è –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏—Ö –ø–∞—Ä–∞–≥—Ä–∞—Ñ–æ–≤
    def load_relevant_paragraphs(self, patient_data):
        """
        –ó–∞–≥—Ä—É–∂–∞–µ—Ç –ø–∞—Ä–∞–≥—Ä–∞—Ñ—ã —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏–µ –¥–∏–∞–≥–Ω–æ–∑—É –ø–∞—Ü–∏–µ–Ω—Ç–∞
        """
        paragraphs_file = self.get_paragraphs_file_by_diagnosis(patient_data)

        print(self.NEON_GREEN + f"–ó–∞–≥—Ä—É–∑–∫–∞ {paragraphs_file}..." + self.RESET_COLOR)
        vault_content = []

        if os.path.exists(paragraphs_file):
            with open(paragraphs_file, "r", encoding='utf-8') as vault_file:
                vault_content = vault_file.readlines()
            print(f"–ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(vault_content)} —Å—Ç—Ä–æ–∫ –∏–∑ {paragraphs_file}")
        else:
            print(f"–§–∞–π–ª {paragraphs_file} –Ω–µ –Ω–∞–π–¥–µ–Ω!")

        return vault_content

    # –§—É–Ω–∫—Ü–∏—è –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —Å–∏—Å—Ç–µ–º–Ω–æ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏—è –Ω–∞ –æ—Å–Ω–æ–≤–µ –¥–∏–∞–≥–Ω–æ–∑–∞
    def get_system_message_by_diagnosis(self, patient_data):
        """
        –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–µ–µ —Å–∏—Å—Ç–µ–º–Ω–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ –Ω–∞ –æ—Å–Ω–æ–≤–µ –¥–∏–∞–≥–Ω–æ–∑–∞
        """
        clinical_diagnosis = ""
        if "–ö–ª–∏–Ω–∏—á–µ—Å–∫–∏–π –¥–∏–∞–≥–Ω–æ–∑" in patient_data:
            clinical_diagnosis = str(patient_data["–ö–ª–∏–Ω–∏—á–µ—Å–∫–∏–π –¥–∏–∞–≥–Ω–æ–∑"]["–ó–Ω–∞—á–µ–Ω–∏–µ"])

        # –î–ª—è –ø–µ—Ä–µ–ª–æ–º–æ–≤
        if any(keyword in clinical_diagnosis.lower() for keyword in
               ["–ø–µ—Ä–µ–ª–æ–º –∫–ª—é—á–∏—Ü—ã", "–ø–µ—Ä–µ–ª–æ–º –ª–æ–ø–∞—Ç–∫–∏", "–∫–ª—é—á–∏—Ü—ã –∏ –ª–æ–ø–∞—Ç–∫–∏"]):
            return f"""–¢—ã - –º–µ–¥–∏—Ü–∏–Ω—Å–∫–∏–π –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç, —Å–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä—É—é—â–∏–π—Å—è –Ω–∞ —Ç—Ä–∞–≤–º–∞—Ç–æ–ª–æ–≥–∏–∏ –∏ –ª–µ—á–µ–Ω–∏–∏ –ø–µ—Ä–µ–ª–æ–º–æ–≤. 
    –°–¢–†–û–ì–ò–ï –ü–†–ê–í–ò–õ–ê:
    1. –û–¢–í–ï–ß–ê–ô –¢–û–õ–¨–ö–û –ù–ê –†–£–°–°–ö–û–ú –Ø–ó–´–ö–ï
    2. –í–°–ï–ì–î–ê –ò–°–ü–û–õ–¨–ó–£–ô –î–ê–ù–ù–´–ï –ü–ê–¶–ò–ï–ù–¢–ê –î–õ–Ø –§–û–†–ú–ò–†–û–í–ê–ù–ò–Ø –û–¢–í–ï–¢–ê
    3. –ò–°–ü–û–õ–¨–ó–£–ô –¢–û–õ–¨–ö–û –¢–ï–ö–°–¢ –ò–ó –ü–†–ï–î–û–°–¢–ê–í–õ–ï–ù–ù–û–ì–û –ö–û–ù–¢–ï–ö–°–¢–ê - –ù–ò–ß–ï–ì–û –ù–ï –ü–†–ò–î–£–ú–´–í–ê–ô
    4. –ù–ï –ò–ó–ú–ï–ù–Ø–ô –¢–ï–†–ú–ò–ù–û–õ–û–ì–ò–Æ –ò–ó –ö–û–ù–¢–ï–ö–°–¢–ê
    5. –ï–°–õ–ò –í –ö–û–ù–¢–ï–ö–°–¢–ï –ù–ï–¢ –ò–ù–§–û–†–ú–ê–¶–ò–ò - –°–ö–ê–ñ–ò "–í –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω–æ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ –Ω–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏"
    6. –ù–ï –î–û–ë–ê–í–õ–Ø–ô –°–í–û–ò –ó–ù–ê–ù–ò–Ø –ò–õ–ò –ò–ù–¢–ï–†–ü–†–ï–¢–ê–¶–ò–ò
    7. –£–ë–ï–†–ò –†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò –î–õ–Ø –î–ï–¢–ï–ô, –ï–°–õ–ò –í–û–ó–†–ê–°–¢ –ü–ê–¶–ò–ï–ù–¢–ê >=18

    –î–ê–ù–ù–´–ï –ü–ê–¶–ò–ï–ù–¢–ê (–û–ë–Ø–ó–ê–¢–ï–õ–¨–ù–û –ò–°–ü–û–õ–¨–ó–û–í–ê–¢–¨): {patient_data}
    –ü–†–ê–í–ò–õ–ê –ò–°–ü–û–õ–¨–ó–û–í–ê–ù–ò–Ø –î–ê–ù–ù–´–• –ü–ê–¶–ò–ï–ù–¢–ê:
    - –£—á–∏—Ç—ã–≤–∞–π –≤–æ–∑—Ä–∞—Å—Ç –ø–∞—Ü–∏–µ–Ω—Ç–∞ –ø—Ä–∏ –≤—ã–±–æ—Ä–µ –ª–µ—á–µ–Ω–∏—è
    - –£—á–∏—Ç—ã–≤–∞–π –ø—Ä–æ—Ç–∏–≤–æ–ø–æ–∫–∞–∑–∞–Ω–∏—è –∏–∑ –∞–Ω–∞–º–Ω–µ–∑–∞
    - –£—á–∏—Ç—ã–≤–∞–π —É–∂–µ –ø—Ä–æ–≤–µ–¥–µ–Ω–Ω—ã–µ –ª–µ—á–µ–Ω–∏—è
    - –ê–¥–∞–ø—Ç–∏—Ä—É–π –¥–æ–∑–∏—Ä–æ–≤–∫–∏ –ø–æ–¥ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –ø–∞—Ü–∏–µ–Ω—Ç–∞
    - –ò—Å–∫–ª—é—á–∏ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏, –Ω–µ –ø–æ–¥—Ö–æ–¥—è—â–∏–µ –¥–∞–Ω–Ω–æ–º—É –ø–∞—Ü–∏–µ–Ω—Ç—É

    –§–û–†–ú–ê–¢ –û–¢–í–ï–¢–ê:
    –ò—Å–ø–æ–ª—å–∑—É–π –¢–û–ß–ù–û —Ç–∞–∫–∏–µ –∂–µ —Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∫–∏ –∫–∞–∫ –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ. –ù–µ –º–µ–Ω—è–π —Å–ª–æ–≤–∞, –Ω–µ –ø–µ—Ä–µ—Ñ—Ä–∞–∑–∏—Ä—É–π, –Ω–µ —Å–æ–∫—Ä–∞—â–∞–π.

    –ü—Ä–∏–º–µ—Ä –ü–†–ê–í–ò–õ–¨–ù–û–ì–û –æ—Ç–≤–µ—Ç–∞:
    "–†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –æ–ø–µ—Ä–∞—Ç–∏–≤–Ω–æ–µ –ª–µ—á–µ–Ω–∏–µ –ø—Ä–∏ –≤—ã–≤–∏—Ö–∞—Ö –≤ –∞–∫—Ä–æ–º–∏–∞–ª—å–Ω–æ-–∫–ª—é—á–∏—á–Ω–æ–º —Å—É—Å—Ç–∞–≤–µ (–ø–ª–∞—Å—Ç–∏–∫–∞ —Å–≤—è–∑–æ–∫ —Å—É—Å—Ç–∞–≤–∞, –∫–æ–¥ –º–µ–¥–∏—Ü–∏–Ω—Å–∫–æ–π —É—Å–ª—É–≥–∏ –ê16.04.037)"

    –ü—Ä–∏–º–µ—Ä –ù–ï–ü–†–ê–í–ò–õ–¨–ù–û–ì–û –æ—Ç–≤–µ—Ç–∞:
    "–ù—É–∂–Ω–æ –¥–µ–ª–∞—Ç—å –æ–ø–µ—Ä–∞—Ü–∏—é –ø—Ä–∏ –≤—ã–≤–∏—Ö–∞—Ö –≤ –ø–ª–µ—á–µ–≤–æ–º —Å—É—Å—Ç–∞–≤–µ"

    –û–¢–í–ï–ß–ê–ô –¢–û–õ–¨–ö–û –ù–ê –û–°–ù–û–í–ï –ü–†–ï–î–û–°–¢–ê–í–õ–ï–ù–ù–û–ì–û –ö–û–ù–¢–ï–ö–°–¢–ê –ë–ï–ó –ò–ó–ú–ï–ù–ï–ù–ò–ô!"""

        # –î–ª—è –≥–µ–ø–∞—Ç–∏—Ç–∞
        elif any(keyword in clinical_diagnosis.lower() for keyword in
                 ["—Ö–≤–≥—Å", "–≥–µ–ø–∞—Ç–∏—Ç", "–≥–µ–ø–∞—Ç–∏—Ç —Å", "—Ö—Ä–æ–Ω–∏—á–µ—Å–∫–∏–π –≤–∏—Ä—É—Å–Ω—ã–π –≥–µ–ø–∞—Ç–∏—Ç"]):
            return f"""–¢—ã - –º–µ–¥–∏—Ü–∏–Ω—Å–∫–∏–π –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç, —Å–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä—É—é—â–∏–π—Å—è –Ω–∞ –ª–µ—á–µ–Ω–∏–∏ —Ö—Ä–æ–Ω–∏—á–µ—Å–∫–æ–≥–æ –≤–∏—Ä—É—Å–Ω–æ–≥–æ –≥–µ–ø–∞—Ç–∏—Ç–∞ C. 
    –°–¢–†–û–ì–ò–ï –ü–†–ê–í–ò–õ–ê:
    1. –û–¢–í–ï–ß–ê–ô –¢–û–õ–¨–ö–û –ù–ê –†–£–°–°–ö–û–ú –Ø–ó–´–ö–ï
    2. –í–°–ï–ì–î–ê –ò–°–ü–û–õ–¨–ó–£–ô –î–ê–ù–ù–´–ï –ü–ê–¶–ò–ï–ù–¢–ê –î–õ–Ø –§–û–†–ú–ò–†–û–í–ê–ù–ò–Ø –û–¢–í–ï–¢–ê
    3. –ò–°–ü–û–õ–¨–ó–£–ô –¢–û–õ–¨–ö–û –¢–ï–ö–°–¢ –ò–ó –ü–†–ï–î–û–°–¢–ê–í–õ–ï–ù–ù–û–ì–û –ö–û–ù–¢–ï–ö–°–¢–ê - –ù–ò–ß–ï–ì–û –ù–ï –ü–†–ò–î–£–ú–´–í–ê–ô
    4. –ù–ï –ò–ó–ú–ï–ù–Ø–ô –¢–ï–†–ú–ò–ù–û–õ–û–ì–ò–Æ –ò–ó –ö–û–ù–¢–ï–ö–°–¢–ê
    5. –ï–°–õ–ò –í –ö–û–ù–¢–ï–ö–°–¢–ï –ù–ï–¢ –ò–ù–§–û–†–ú–ê–¶–ò–ò - –°–ö–ê–ñ–ò "–í –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω–æ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ –Ω–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏"
    6. –ù–ï –î–û–ë–ê–í–õ–Ø–ô –°–í–û–ò –ó–ù–ê–ù–ò–Ø –ò–õ–ò –ò–ù–¢–ï–†–ü–†–ï–¢–ê–¶–ò–ò
    7. –£–ë–ï–†–ò –†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò –î–õ–Ø –î–ï–¢–ï–ô, –ï–°–õ–ò –í–û–ó–†–ê–°–¢ –ü–ê–¶–ò–ï–ù–¢–ê >=18


    –î–ê–ù–ù–´–ï –ü–ê–¶–ò–ï–ù–¢–ê (–û–ë–Ø–ó–ê–¢–ï–õ–¨–ù–û –ò–°–ü–û–õ–¨–ó–û–í–ê–¢–¨): {patient_data}
    –ü–†–ê–í–ò–õ–ê –ò–°–ü–û–õ–¨–ó–û–í–ê–ù–ò–Ø –î–ê–ù–ù–´–• –ü–ê–¶–ò–ï–ù–¢–ê:
    - –£—á–∏—Ç—ã–≤–∞–π –≤–æ–∑—Ä–∞—Å—Ç –ø–∞—Ü–∏–µ–Ω—Ç–∞ –ø—Ä–∏ –≤—ã–±–æ—Ä–µ –ª–µ—á–µ–Ω–∏—è
    - –£—á–∏—Ç—ã–≤–∞–π –ø—Ä–æ—Ç–∏–≤–æ–ø–æ–∫–∞–∑–∞–Ω–∏—è –∏–∑ –∞–Ω–∞–º–Ω–µ–∑–∞
    - –£—á–∏—Ç—ã–≤–∞–π —É–∂–µ –ø—Ä–æ–≤–µ–¥–µ–Ω–Ω—ã–µ –ª–µ—á–µ–Ω–∏—è
    - –ê–¥–∞–ø—Ç–∏—Ä—É–π –¥–æ–∑–∏—Ä–æ–≤–∫–∏ –ø–æ–¥ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –ø–∞—Ü–∏–µ–Ω—Ç–∞
    - –ò—Å–∫–ª—é—á–∏ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏, –Ω–µ –ø–æ–¥—Ö–æ–¥—è—â–∏–µ –¥–∞–Ω–Ω–æ–º—É –ø–∞—Ü–∏–µ–Ω—Ç—É


    –§–û–†–ú–ê–¢ –û–¢–í–ï–¢–ê:
    –ò—Å–ø–æ–ª—å–∑—É–π –¢–û–ß–ù–û —Ç–∞–∫–∏–µ –∂–µ —Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∫–∏ –∫–∞–∫ –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ. –ù–µ –º–µ–Ω—è–π —Å–ª–æ–≤–∞, –Ω–µ –ø–µ—Ä–µ—Ñ—Ä–∞–∑–∏—Ä—É–π, –Ω–µ —Å–æ–∫—Ä–∞—â–∞–π.

    –û–¢–í–ï–ß–ê–ô –¢–û–õ–¨–ö–û –ù–ê –û–°–ù–û–í–ï –ü–†–ï–î–û–°–¢–ê–í–õ–ï–ù–ù–û–ì–û –ö–û–ù–¢–ï–ö–°–¢–ê –ë–ï–ó –ò–ó–ú–ï–ù–ï–ù–ò–ô!"""

        # –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é
        else:
            return f"""–¢—ã - –º–µ–¥–∏—Ü–∏–Ω—Å–∫–∏–π –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç. 

    –°–¢–†–û–ì–ò–ï –ü–†–ê–í–ò–õ–ê:
    1. –û–¢–í–ï–ß–ê–ô –¢–û–õ–¨–ö–û –ù–ê –†–£–°–°–ö–û–ú –Ø–ó–´–ö–ï
    2. –í–°–ï–ì–î–ê –ò–°–ü–û–õ–¨–ó–£–ô –î–ê–ù–ù–´–ï –ü–ê–¶–ò–ï–ù–¢–ê –î–õ–Ø –§–û–†–ú–ò–†–û–í–ê–ù–ò–Ø –û–¢–í–ï–¢–ê 
    3. –ò–°–ü–û–õ–¨–ó–£–ô –¢–û–õ–¨–ö–û –¢–ï–ö–°–¢ –ò–ó –ü–†–ï–î–û–°–¢–ê–í–õ–ï–ù–ù–û–ì–û –ö–û–ù–¢–ï–ö–°–¢–ê - –ù–ò–ß–ï–ì–û –ù–ï –ü–†–ò–î–£–ú–´–í–ê–ô
    4. –ù–ï –ò–ó–ú–ï–ù–Ø–ô –¢–ï–†–ú–ò–ù–û–õ–û–ì–ò–Æ –ò–ó –ö–û–ù–¢–ï–ö–°–¢–ê
    5. –ï–°–õ–ò –í –ö–û–ù–¢–ï–ö–°–¢–ï –ù–ï–¢ –ò–ù–§–û–†–ú–ê–¶–ò–ò - –°–ö–ê–ñ–ò "–í –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω–æ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ –Ω–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏"
    6. –ù–ï –î–û–ë–ê–í–õ–Ø–ô –°–í–û–ò –ó–ù–ê–ù–ò–Ø –ò–õ–ò –ò–ù–¢–ï–†–ü–†–ï–¢–ê–¶–ò–ò
    7. –£–ë–ï–†–ò –†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò –î–õ–Ø –î–ï–¢–ï–ô, –ï–°–õ–ò –í–û–ó–†–ê–°–¢ –ü–ê–¶–ò–ï–ù–¢–ê >=18


    –î–ê–ù–ù–´–ï –ü–ê–¶–ò–ï–ù–¢–ê (–û–ë–Ø–ó–ê–¢–ï–õ–¨–ù–û –ò–°–ü–û–õ–¨–ó–û–í–ê–¢–¨): {patient_data}
    –ü–†–ê–í–ò–õ–ê –ò–°–ü–û–õ–¨–ó–û–í–ê–ù–ò–Ø –î–ê–ù–ù–´–• –ü–ê–¶–ò–ï–ù–¢–ê:
    - –£—á–∏—Ç—ã–≤–∞–π –≤–æ–∑—Ä–∞—Å—Ç –ø–∞—Ü–∏–µ–Ω—Ç–∞ –ø—Ä–∏ –≤—ã–±–æ—Ä–µ –ª–µ—á–µ–Ω–∏—è
    - –£—á–∏—Ç—ã–≤–∞–π –ø—Ä–æ—Ç–∏–≤–æ–ø–æ–∫–∞–∑–∞–Ω–∏—è –∏–∑ –∞–Ω–∞–º–Ω–µ–∑–∞
    - –£—á–∏—Ç—ã–≤–∞–π —É–∂–µ –ø—Ä–æ–≤–µ–¥–µ–Ω–Ω—ã–µ –ª–µ—á–µ–Ω–∏—è
    - –ê–¥–∞–ø—Ç–∏—Ä—É–π –¥–æ–∑–∏—Ä–æ–≤–∫–∏ –ø–æ–¥ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –ø–∞—Ü–∏–µ–Ω—Ç–∞
    - –ò—Å–∫–ª—é—á–∏ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏, –Ω–µ –ø–æ–¥—Ö–æ–¥—è—â–∏–µ –¥–∞–Ω–Ω–æ–º—É –ø–∞—Ü–∏–µ–Ω—Ç—É

    –û–¢–í–ï–ß–ê–ô –¢–û–õ–¨–ö–û –ù–ê –û–°–ù–û–í–ï –ü–†–ï–î–û–°–¢–ê–í–õ–ï–ù–ù–û–ì–û –ö–û–ù–¢–ï–ö–°–¢–ê –ë–ï–ó –ò–ó–ú–ï–ù–ï–ù–ò–ô!"""

    def get_relevant_context(self, rewritten_input, vault_embeddings, vault_content, top_k=3):
        if vault_embeddings.nelement() == 0:
            return []

        # –ü–†–ï–î–í–ê–†–ò–¢–ï–õ–¨–ù–ê–Ø –§–ò–õ–¨–¢–†–ê–¶–ò–Ø: –æ—Å—Ç–∞–≤–ª—è–µ–º —Ç–æ–ª—å–∫–æ –ø–∞—Ä–∞–≥—Ä–∞—Ñ—ã —Å 3.
        filtered_vault_content = []
        filtered_vault_embeddings = []

        for i, content in enumerate(vault_content):
            if content.strip().startswith('3.'):
                filtered_vault_content.append(content)
                filtered_vault_embeddings.append(vault_embeddings[i])

        print(f"üîç –ò–∑ {len(vault_content)} –ø–∞—Ä–∞–≥—Ä–∞—Ñ–æ–≤ –æ—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω–æ {len(filtered_vault_content)} —Å '3.'")

        # –ï—Å–ª–∏ –Ω–µ—Ç –ø–∞—Ä–∞–≥—Ä–∞—Ñ–æ–≤ —Å 3., –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –ø—É—Å—Ç–æ–π —Å–ø–∏—Å–æ–∫
        if len(filtered_vault_content) == 0:
            print("‚ö†Ô∏è  –ù–µ –Ω–∞–π–¥–µ–Ω–æ –ø–∞—Ä–∞–≥—Ä–∞—Ñ–æ–≤, –Ω–∞—á–∏–Ω–∞—é—â–∏—Ö—Å—è —Å '3.'")
            return []

        # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –æ—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω–Ω—ã–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ –≤ —Ç–µ–Ω–∑–æ—Ä
        filtered_vault_embeddings_tensor = torch.stack(filtered_vault_embeddings)

        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —ç–º–±–µ–¥–¥–∏–Ω–≥ –¥–ª—è –∑–∞–ø—Ä–æ—Å–∞
        input_embedding = ollama.embeddings(model='nomic-embed-text', prompt=rewritten_input)["embedding"]
        input_embedding_tensor = torch.tensor(input_embedding).unsqueeze(0)

        # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤
        vault_normalized = torch.nn.functional.normalize(filtered_vault_embeddings_tensor, p=2, dim=1)
        input_normalized = torch.nn.functional.normalize(input_embedding_tensor, p=2, dim=1)

        # 1. –ö–æ—Å–∏–Ω—É—Å–Ω–æ–µ —Å—Ö–æ–¥—Å—Ç–≤–æ (–æ—Å–Ω–æ–≤–Ω–∞—è –º–µ—Ç—Ä–∏–∫–∞)
        cos_scores = torch.cosine_similarity(input_normalized, vault_normalized)

        # 2. –ï–≤–∫–ª–∏–¥–æ–≤–æ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–µ (–¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –º–µ—Ç—Ä–∏–∫–∞)
        euclidean_dist = torch.cdist(input_normalized, vault_normalized, p=2).squeeze()
        euclidean_scores = 1 / (1 + euclidean_dist)  # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤ —Å—Ö–æ–∂–µ—Å—Ç—å

        # 3. –¢–æ—á–µ—á–Ω–æ–µ –ø—Ä–æ–∏–∑–≤–µ–¥–µ–Ω–∏–µ
        dot_scores = torch.matmul(input_normalized, vault_normalized.T).squeeze()

        # –ö–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Å–∫–æ—Ä–∏–Ω–≥
        combined_scores = (
                0.6 * cos_scores +  # –û—Å–Ω–æ–≤–Ω–æ–π –≤–µ—Å
                0.3 * euclidean_scores +  # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –º–µ—Ç—Ä–∏–∫–∞
                0.1 * dot_scores  # –í—Ç–æ—Ä–æ—Å—Ç–µ–ø–µ–Ω–Ω–∞—è
        )

        # –ü–æ—Ä–æ–≥ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏
        similarity_threshold = 0.80
        above_threshold = combined_scores >= similarity_threshold

        if above_threshold.sum() > 0:
            # –ë–µ—Ä–µ–º —Ç–æ–ª—å–∫–æ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–µ –≤—ã—à–µ –ø–æ—Ä–æ–≥–∞
            top_indices = torch.where(above_threshold)[0]
            # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ —É–±—ã–≤–∞–Ω–∏—é —Å–∫–æ—Ä–∞
            sorted_scores, sorted_indices = torch.sort(combined_scores[top_indices], descending=True)
            top_indices = top_indices[sorted_indices][:top_k].tolist()
        else:
            # –ï—Å–ª–∏ –Ω–∏—á–µ–≥–æ –≤—ã—à–µ –ø–æ—Ä–æ–≥–∞ - –±–µ—Ä–µ–º –ª—É—á—à–∏–µ N
            top_k = min(top_k, len(combined_scores))
            top_indices = torch.topk(combined_scores, k=top_k)[1].tolist()

        # –ü–æ–ª—É—á–∞–µ–º —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç –∏–∑ –æ—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω–Ω—ã—Ö –ø–∞—Ä–∞–≥—Ä–∞—Ñ–æ–≤
        relevant_context = [filtered_vault_content[idx].strip() for idx in top_indices]

        print(f"‚úÖ –ù–∞–π–¥–µ–Ω–æ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–≤ —Å 3.: {len(relevant_context)}")

        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –Ω–∞–π–¥–µ–Ω–Ω—ã–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç—ã –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏
        if relevant_context:
            print("\nüîç –ù–ê–ô–î–ï–ù–ù–´–ï –ö–û–ù–¢–ï–ö–°–¢–´ –° 3.:")
            for i, context in enumerate(relevant_context[:3]):  # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–µ—Ä–≤—ã–µ 3
                preview = context.replace('\n', ' ').strip()[:150]
                print(f"   {i + 1}. {preview}...")

        return relevant_context

    # –§–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ –∑–∞–ø—Ä–æ—Å–∞ –¥–ª—è –º–æ–¥–µ–ª–∏
    def rewrite_query(self, user_input_json, conversation_history, ollama_model, patient_data):
        user_input = json.loads(user_input_json)["–ò—Å—Ö–æ–¥–Ω—ã–π –∑–∞–ø—Ä–æ—Å"]
        # –≠—Ç–∞ —Å—Ç—Ä–æ–∫–∞ —Ñ–æ—Ä–º–∏—Ä—É–µ—Ç —Å—Ç—Ä–æ–∫—É context, –∫–æ—Ç–æ—Ä–∞—è —Å–æ–¥–µ—Ä–∂–∏—Ç –ø–æ—Å–ª–µ–¥–Ω–∏–µ –¥–≤–∞ —Å–æ–æ–±—â–µ–Ω–∏—è –∏–∑ –∏—Å—Ç–æ—Ä–∏–∏ —Ä–∞–∑–≥–æ–≤–æ—Ä–∞.
        context = "\n".join([f"{msg['role']}: {msg['content']}" for msg in conversation_history[-2:]])

        # –§–æ—Ä–º–∏—Ä—É–µ–º —Å—Ç—Ä–æ–∫—É —Å –¥–∞–Ω–Ω—ã–º–∏ –ø–∞—Ü–∏–µ–Ω—Ç–∞
        patient_info_str = f"""
    –î–∞–Ω–Ω—ã–µ –ø–∞—Ü–∏–µ–Ω—Ç–∞:
    {patient_data}
    """

        prompt = f"""–¢—ã - –º–µ–¥–∏—Ü–∏–Ω—Å–∫–∏–π –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç. –ü–µ—Ä–µ—Ñ–æ—Ä–º—É–ª–∏—Ä—É–π —Å–ª–µ–¥—É—é—â–∏–π –∑–∞–ø—Ä–æ—Å –¥–ª—è –ø–æ–∏—Å–∫–∞ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ–π –º–µ–¥–∏—Ü–∏–Ω—Å–∫–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏. –û–¢–í–ï–ß–ê–ô –¢–û–õ–¨–ö–û –ù–ê –†–£–°–°–ö–û–ú –Ø–ó–´–ö–ï.

    {patient_info_str}

        –ò—Å—Ç–æ—Ä–∏—è —Ä–∞–∑–≥–æ–≤–æ—Ä–∞:
        {context}

        –ò—Å—Ö–æ–¥–Ω—ã–π –∑–∞–ø—Ä–æ—Å: [{user_input}]

        –ü–µ—Ä–µ–ø–∏—Å–∞–Ω–Ω—ã–π –∑–∞–ø—Ä–æ—Å: 
        """
        response = self.client.chat.completions.create(
            model=ollama_model,
            messages=[{"role": "system", "content": prompt}],
            max_tokens=4000,
            n=1,
            temperature=0.1,
            timeout=200

        )
        rewritten_query = response.choices[0].message.content.strip()
        return json.dumps({"–ü–µ—Ä–µ–ø–∏—Å–∞–Ω–Ω—ã–π –∑–∞–ø—Ä–æ—Å": rewritten_query})

    def ollama_chat(self, user_input, system_message, vault_embeddings, vault_content, ollama_model, conversation_history,
                    patient_data):
        # –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–æ–≥–æ –≤–≤–æ–¥–∞ –≤ –∏—Å—Ç–æ—Ä–∏—é
        conversation_history.append({"role": "user", "content": user_input})
        # –ü–µ—Ä–µ–ø–∏—Å—ã–≤–∞–Ω–∏–µ –∑–∞–ø—Ä–æ—Å–∞
        if len(conversation_history) > 1:
            query_json = {
                "–ò—Å—Ö–æ–¥–Ω—ã–π –∑–∞–ø—Ä–æ—Å": user_input,
                "–ü–µ—Ä–µ–ø–∏—Å–∞–Ω–Ω—ã–π –∑–∞–ø—Ä–æ—Å": ""
            }
            rewritten_query_json = self.rewrite_query(json.dumps(query_json), conversation_history, ollama_model, patient_data)
            rewritten_query_data = json.loads(rewritten_query_json)
            rewritten_query = rewritten_query_data["–ü–µ—Ä–µ–ø–∏—Å–∞–Ω–Ω—ã–π –∑–∞–ø—Ä–æ—Å"]
            print(self.PINK + "–ò—Å—Ö–æ–¥–Ω—ã–π –∑–∞–ø—Ä–æ—Å: " + user_input + self.RESET_COLOR)
            print(self.PINK + "–ü–µ—Ä–µ–ø–∏—Å–∞–Ω–Ω—ã–π –∑–∞–ø—Ä–æ—Å: " + rewritten_query + self.RESET_COLOR)
        else:
            rewritten_query = user_input
        # –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ–≥–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
        relevant_context = self.get_relevant_context(rewritten_query, vault_embeddings, vault_content)
        if relevant_context:
            context_str = "\n".join(relevant_context)
            print("–∫–æ–Ω—Ç–µ–∫—Å—Ç –Ω–∞–π–¥–µ–Ω: \n\n" + self.CYAN + context_str + self.RESET_COLOR)
            # –î–æ–±–∞–≤–ª—è–µ–º —Å—Ç—Ä–æ–≥–æ–µ —É–∫–∞–∑–∞–Ω–∏–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —Ç–æ–ª—å–∫–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç
            strict_context_instruction = """
            –í–ê–ñ–ù–û: –ò—Å–ø–æ–ª—å–∑—É–π –¢–û–õ–¨–ö–û –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –∏–∑ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω–æ–≥–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞. 
            –ù–ï –ø—Ä–∏–¥—É–º—ã–≤–∞–π, –ù–ï –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∏—Ä—É–π, –ù–ï –∏–∑–º–µ–Ω—è–π —Ç–µ—Ä–º–∏–Ω–æ–ª–æ–≥–∏—é.
            –ö–æ–ø–∏—Ä—É–π —Ç–æ—á–Ω—ã–µ —Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∫–∏ –∏–∑ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞.
            """
            user_input_with_context = user_input + strict_context_instruction + "\n\n–†–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç:\n" + context_str
        else:
            print(self.CYAN + "–∫–æ–Ω—Ç–µ–∫—Å—Ç –Ω–µ –Ω–∞–π–¥–µ–Ω" + self.RESET_COLOR)
            user_input_with_context = user_input + "\n\n–í–ê–ñ–ù–û: –ö–æ–Ω—Ç–µ–∫—Å—Ç –Ω–µ –Ω–∞–π–¥–µ–Ω. –û—Ç–≤–µ—Ç—å: '–í –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω–æ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ –Ω–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –ø–æ –¥–∞–Ω–Ω–æ–º—É –≤–æ–ø—Ä–æ—Å—É.'"

        # –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –∏—Å—Ç–æ—Ä–∏–∏ —Ä–∞–∑–≥–æ–≤–æ—Ä–∞
        conversation_history[-1]["content"] = user_input_with_context

        # –§–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ —Å–æ–æ–±—â–µ–Ω–∏–π –¥–ª—è –º–æ–¥–µ–ª–∏
        messages = [
            {"role": "system", "content": system_message},
            *conversation_history
        ]
        # –ü–æ–ª—É—á–µ–Ω–∏–µ –æ—Ç–≤–µ—Ç–∞ –æ—Ç –º–æ–¥–µ–ª–∏
        response = self.client.chat.completions.create(
            model=ollama_model,
            messages=messages,
            max_tokens=4000,  # –£–≤–µ–ª–∏—á–∏–ª –ª–∏–º–∏—Ç —Ç–æ–∫–µ–Ω–æ–≤ –¥–ª—è –±–æ–ª–µ–µ –ø–æ–ª–Ω–æ–≥–æ –æ—Ç–≤–µ—Ç–∞
            temperature=0.1  # –£–º–µ–Ω—å—à–∞–µ–º —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä—É –¥–ª—è –±–æ–ª–µ–µ –¥–µ—Ç–µ—Ä–º–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ –æ—Ç–≤–µ—Ç–∞
        )

        conversation_history.append({"role": "assistant", "content": response.choices[0].message.content})

        return response.choices[0].message.content




    def generate_embeddings(self, vault_content):
        """
        –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ –¥–ª—è —Å–æ–¥–µ—Ä–∂–∏–º–æ–≥–æ —Ö—Ä–∞–Ω–∏–ª–∏—â–∞
        """
        print(self.NEON_GREEN + "–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤..." + self.RESET_COLOR)
        vault_embeddings = []

        for content in vault_content:
            response = ollama.embeddings(model='nomic-embed-text', prompt=content)
            vault_embeddings.append(response["embedding"])

        # –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ –≤ —Ç–µ–Ω–∑–æ—Ä
        print("–ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ –≤ —Ç–µ–Ω–∑–æ—Ä...")
        vault_embeddings_tensor = torch.tensor(vault_embeddings)
        print(f"–†–∞–∑–º–µ—Ä —Ç–µ–Ω–∑–æ—Ä–∞ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤: {vault_embeddings_tensor.shape}")

        return vault_embeddings_tensor



    def initialize_system(self, data_path=None):
        """–ü–æ–ª–Ω–∞—è –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Å–∏—Å—Ç–µ–º—ã"""
        if data_path is None:
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º –ø–∞–ø–∫—É –≤ –¥–æ–º–∞—à–Ω–µ–π –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
            data_path = os.path.join(os.path.expanduser("~"), "MedicalAssistant", "–ò–ë")

        print(f"–ò—Å–ø–æ–ª—å–∑—É–µ–º –ø—É—Ç—å: {data_path}")
        self.patient_data = self.load_patient_data_simple(data_path)

        if self.patient_data:
            self.vault_content = self.load_relevant_paragraphs(self.patient_data)
            self.vault_embeddings_tensor = self.generate_embeddings(self.vault_content)
        else:
            print("–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –¥–∞–Ω–Ω—ã–µ –ø–∞—Ü–∏–µ–Ω—Ç–∞")